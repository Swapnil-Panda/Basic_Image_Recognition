{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/swapnilpanda/test-job?scriptVersionId=113317275\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing libraries for the code","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten,concatenate \nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras import metrics\n\nfrom sklearn.utils import class_weight\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\n\nfrom os import listdir\nfrom os.path import isfile, join\n\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:53.18608Z","iopub.execute_input":"2022-12-08T20:22:53.186457Z","iopub.status.idle":"2022-12-08T20:22:53.194085Z","shell.execute_reply.started":"2022-12-08T20:22:53.186425Z","shell.execute_reply":"2022-12-08T20:22:53.19307Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Giving address of images","metadata":{}},{"cell_type":"code","source":"train_loc = '/kaggle/input/check3/BF_split/train'\ntest_loc = '/kaggle/input/check3/BF_split/val'\n# test2='pandaimf/swap2/test/'","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:53.196131Z","iopub.execute_input":"2022-12-08T20:22:53.196755Z","iopub.status.idle":"2022-12-08T20:22:53.205061Z","shell.execute_reply.started":"2022-12-08T20:22:53.196719Z","shell.execute_reply":"2022-12-08T20:22:53.204097Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Load the train and test data using ImageDataGenerator flow_from_directory. Target size set to 224x224 given that this is the input requirement of VGG16.**","metadata":{}},{"cell_type":"code","source":"trdata = ImageDataGenerator(rescale=1./255)\ntraindata = trdata.flow_from_directory(directory=train_loc, target_size=(224,224),batch_size=2)\n\ntsdata = ImageDataGenerator(rescale=1./255)\ntestdata = tsdata.flow_from_directory(directory=test_loc, target_size=(224,224),batch_size=2)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:53.208629Z","iopub.execute_input":"2022-12-08T20:22:53.208964Z","iopub.status.idle":"2022-12-08T20:22:53.419852Z","shell.execute_reply.started":"2022-12-08T20:22:53.208928Z","shell.execute_reply":"2022-12-08T20:22:53.418905Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Found 56 images belonging to 3 classes.\nFound 15 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**SHowing data classes**","metadata":{}},{"cell_type":"code","source":"traindata.class_indices","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:53.42099Z","iopub.execute_input":"2022-12-08T20:22:53.421534Z","iopub.status.idle":"2022-12-08T20:22:53.428106Z","shell.execute_reply.started":"2022-12-08T20:22:53.4215Z","shell.execute_reply":"2022-12-08T20:22:53.427077Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'Flat foot': 0, 'Normal': 1, 'ToeFirst': 2}"},"metadata":{}}]},{"cell_type":"markdown","source":"**This part is used for checking**","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.preprocessing import image \n\n# tdata=image.load_img('/kaggle/input/ta-check/Tibialis Anterior_split/val/flatfoot/19.jpg', target_size=(224,224))\n# testd=image.img_to_array(tdata)\n\n# image = np.expand_dims(testd, axis=0)\n# best_model.predict(image)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:53.430717Z","iopub.execute_input":"2022-12-08T20:22:53.431366Z","iopub.status.idle":"2022-12-08T20:22:53.436851Z","shell.execute_reply.started":"2022-12-08T20:22:53.431332Z","shell.execute_reply":"2022-12-08T20:22:53.435732Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**Use the weights from imagenet to get the pretrained model. The prediction is set to 3 output because we have 3 classes.**","metadata":{}},{"cell_type":"code","source":"vgg16 = VGG16(weights='imagenet')\nvgg16.summary()\nx  = vgg16.get_layer('fc2').output\nprediction = Dense(3, activation='softmax', name='predictions1')(x)\n\nmodel = Model(inputs=vgg16.input, outputs=prediction)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:53.438401Z","iopub.execute_input":"2022-12-08T20:22:53.439109Z","iopub.status.idle":"2022-12-08T20:22:59.911903Z","shell.execute_reply.started":"2022-12-08T20:22:53.439073Z","shell.execute_reply":"2022-12-08T20:22:59.910853Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2022-12-08 20:22:53.548340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:53.641505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:53.642242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:53.643429: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-08 20:22:53.643707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:53.644384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:53.645015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:55.982562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:55.983415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:55.984212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-08 20:22:55.984873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467904/553467096 [==============================] - 2s 0us/step\n553476096/553467096 [==============================] - 2s 0us/step\nModel: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions (Dense)          (None, 1000)              4097000   \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Now consider that normally, imagenet is recognising objects. We have spectrogram images which has signals. So we set 20 out of 23 layers to trainable.**","metadata":{}},{"cell_type":"markdown","source":"# run","metadata":{}},{"cell_type":"markdown","source":"# Tibialis Anterior","metadata":{}},{"cell_type":"markdown","source":"**** ** All the model parameters ** ****","metadata":{}},{"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False\n\nfor layer in model.layers[-20:]:\n    layer.trainable = True\n    print(\"Layer '%s' is trainable\" % layer.name) \nopt = Adam(lr=0.00001)\nmodel.compile(optimizer=opt, loss=categorical_crossentropy, \n              metrics=['accuracy', 'mae'])\nmodel.summary()\ncheckpoint = ModelCheckpoint(\"working/vgg16_base_res_QF.h5\", monitor='val_accuracy', verbose=1, \n                             save_best_only=True, save_weights_only=False, mode='auto')\nearly = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\ncounter = Counter(traindata.classes)                       \nmax_val = float(max(counter.values()))   \nclass_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\nclass_weights\n","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:59.913498Z","iopub.execute_input":"2022-12-08T20:22:59.914135Z","iopub.status.idle":"2022-12-08T20:22:59.941362Z","shell.execute_reply.started":"2022-12-08T20:22:59.914096Z","shell.execute_reply":"2022-12-08T20:22:59.940066Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Layer 'block1_pool' is trainable\nLayer 'block2_conv1' is trainable\nLayer 'block2_conv2' is trainable\nLayer 'block2_pool' is trainable\nLayer 'block3_conv1' is trainable\nLayer 'block3_conv2' is trainable\nLayer 'block3_conv3' is trainable\nLayer 'block3_pool' is trainable\nLayer 'block4_conv1' is trainable\nLayer 'block4_conv2' is trainable\nLayer 'block4_conv3' is trainable\nLayer 'block4_pool' is trainable\nLayer 'block5_conv1' is trainable\nLayer 'block5_conv2' is trainable\nLayer 'block5_conv3' is trainable\nLayer 'block5_pool' is trainable\nLayer 'flatten' is trainable\nLayer 'fc1' is trainable\nLayer 'fc2' is trainable\nLayer 'predictions1' is trainable\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions1 (Dense)         (None, 3)                 12291     \n=================================================================\nTotal params: 134,272,835\nTrainable params: 134,234,115\nNon-trainable params: 38,720\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{0: 1.0, 1: 1.75, 2: 2.3333333333333335}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"working/vgg16_base_res_QF.h5\", monitor='val_accuracy', verbose=1, \n                             save_best_only=True, save_weights_only=False, mode='auto')\nhist = model.fit(traindata, steps_per_epoch=traindata.samples//traindata.batch_size, validation_data=testdata,\n                 class_weight=class_weights,\n                   validation_steps=testdata.samples//testdata.batch_size,\n                 epochs=150,callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:22:59.943083Z","iopub.execute_input":"2022-12-08T20:22:59.943816Z","iopub.status.idle":"2022-12-08T20:26:22.264155Z","shell.execute_reply.started":"2022-12-08T20:22:59.943771Z","shell.execute_reply":"2022-12-08T20:26:22.260499Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2022-12-08 20:23:00.070422: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/150\n","output_type":"stream"},{"name":"stderr","text":"2022-12-08 20:23:01.731809: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"28/28 [==============================] - 10s 52ms/step - loss: 2.2679 - accuracy: 0.2857 - mae: 0.4495 - val_loss: 1.1542 - val_accuracy: 0.3571 - val_mae: 0.4371\n\nEpoch 00001: val_accuracy improved from -inf to 0.35714, saving model to working/vgg16_base_res_QF.h5\nEpoch 2/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.8572 - accuracy: 0.3036 - mae: 0.4552 - val_loss: 1.4585 - val_accuracy: 0.2857 - val_mae: 0.4382\n\nEpoch 00002: val_accuracy did not improve from 0.35714\nEpoch 3/150\n28/28 [==============================] - 1s 39ms/step - loss: 2.0709 - accuracy: 0.3214 - mae: 0.4410 - val_loss: 1.2891 - val_accuracy: 0.2857 - val_mae: 0.4693\n\nEpoch 00003: val_accuracy did not improve from 0.35714\nEpoch 4/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.7310 - accuracy: 0.4286 - mae: 0.4035 - val_loss: 1.0924 - val_accuracy: 0.2857 - val_mae: 0.4247\n\nEpoch 00004: val_accuracy did not improve from 0.35714\nEpoch 5/150\n28/28 [==============================] - 2s 58ms/step - loss: 1.4623 - accuracy: 0.4464 - mae: 0.4087 - val_loss: 1.3266 - val_accuracy: 0.5000 - val_mae: 0.3694\n\nEpoch 00005: val_accuracy improved from 0.35714 to 0.50000, saving model to working/vgg16_base_res_QF.h5\nEpoch 6/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.7844 - accuracy: 0.4107 - mae: 0.3954 - val_loss: 1.1067 - val_accuracy: 0.5000 - val_mae: 0.3528\n\nEpoch 00006: val_accuracy did not improve from 0.50000\nEpoch 7/150\n28/28 [==============================] - 1s 43ms/step - loss: 1.0316 - accuracy: 0.6071 - mae: 0.3058 - val_loss: 1.1192 - val_accuracy: 0.3571 - val_mae: 0.3534\n\nEpoch 00007: val_accuracy did not improve from 0.50000\nEpoch 8/150\n28/28 [==============================] - 1s 38ms/step - loss: 0.5587 - accuracy: 0.8214 - mae: 0.1930 - val_loss: 1.0999 - val_accuracy: 0.5000 - val_mae: 0.3501\n\nEpoch 00008: val_accuracy did not improve from 0.50000\nEpoch 9/150\n28/28 [==============================] - 1s 38ms/step - loss: 0.6266 - accuracy: 0.7500 - mae: 0.1732 - val_loss: 0.8987 - val_accuracy: 0.7143 - val_mae: 0.2242\n\nEpoch 00009: val_accuracy improved from 0.50000 to 0.71429, saving model to working/vgg16_base_res_QF.h5\nEpoch 10/150\n28/28 [==============================] - 1s 39ms/step - loss: 0.2353 - accuracy: 0.9643 - mae: 0.0925 - val_loss: 0.8768 - val_accuracy: 0.7143 - val_mae: 0.2224\n\nEpoch 00010: val_accuracy did not improve from 0.71429\nEpoch 11/150\n28/28 [==============================] - 1s 39ms/step - loss: 0.5627 - accuracy: 0.8214 - mae: 0.1440 - val_loss: 0.6375 - val_accuracy: 0.7857 - val_mae: 0.1858\n\nEpoch 00011: val_accuracy improved from 0.71429 to 0.78571, saving model to working/vgg16_base_res_QF.h5\nEpoch 12/150\n28/28 [==============================] - 1s 39ms/step - loss: 0.2224 - accuracy: 0.9286 - mae: 0.0792 - val_loss: 1.1740 - val_accuracy: 0.6429 - val_mae: 0.2265\n\nEpoch 00012: val_accuracy did not improve from 0.78571\nEpoch 13/150\n28/28 [==============================] - 1s 39ms/step - loss: 0.1376 - accuracy: 0.9643 - mae: 0.0524 - val_loss: 1.3181 - val_accuracy: 0.6429 - val_mae: 0.2711\n\nEpoch 00013: val_accuracy did not improve from 0.78571\nEpoch 14/150\n28/28 [==============================] - 1s 38ms/step - loss: 0.0224 - accuracy: 1.0000 - mae: 0.0112 - val_loss: 1.3491 - val_accuracy: 0.6429 - val_mae: 0.2388\n\nEpoch 00014: val_accuracy did not improve from 0.78571\nEpoch 15/150\n28/28 [==============================] - 1s 38ms/step - loss: 0.0079 - accuracy: 1.0000 - mae: 0.0042 - val_loss: 1.1848 - val_accuracy: 0.7143 - val_mae: 0.2090\n\nEpoch 00015: val_accuracy did not improve from 0.78571\nEpoch 16/150\n28/28 [==============================] - 1s 38ms/step - loss: 0.0054 - accuracy: 1.0000 - mae: 0.0028 - val_loss: 1.5571 - val_accuracy: 0.6429 - val_mae: 0.2545\n\nEpoch 00016: val_accuracy did not improve from 0.78571\nEpoch 17/150\n28/28 [==============================] - 1s 38ms/step - loss: 0.0036 - accuracy: 1.0000 - mae: 0.0020 - val_loss: 1.0442 - val_accuracy: 0.7143 - val_mae: 0.2007\n\nEpoch 00017: val_accuracy did not improve from 0.78571\nEpoch 18/150\n28/28 [==============================] - 1s 39ms/step - loss: 0.0027 - accuracy: 1.0000 - mae: 0.0014 - val_loss: 1.6705 - val_accuracy: 0.6429 - val_mae: 0.2498\n\nEpoch 00018: val_accuracy did not improve from 0.78571\nEpoch 19/150\n28/28 [==============================] - 1s 43ms/step - loss: 0.0019 - accuracy: 1.0000 - mae: 0.0011 - val_loss: 1.5628 - val_accuracy: 0.7143 - val_mae: 0.2053\n\nEpoch 00019: val_accuracy did not improve from 0.78571\nEpoch 20/150\n28/28 [==============================] - 1s 39ms/step - loss: 0.0015 - accuracy: 1.0000 - mae: 8.1032e-04 - val_loss: 1.5997 - val_accuracy: 0.7143 - val_mae: 0.2027\n\nEpoch 00020: val_accuracy did not improve from 0.78571\nEpoch 21/150\n28/28 [==============================] - 1s 38ms/step - loss: 0.0011 - accuracy: 1.0000 - mae: 6.2713e-04 - val_loss: 1.8617 - val_accuracy: 0.6429 - val_mae: 0.2472\n\nEpoch 00021: val_accuracy did not improve from 0.78571\nEpoch 22/150\n28/28 [==============================] - 1s 38ms/step - loss: 8.9725e-04 - accuracy: 1.0000 - mae: 5.0570e-04 - val_loss: 1.9189 - val_accuracy: 0.6429 - val_mae: 0.2469\n\nEpoch 00022: val_accuracy did not improve from 0.78571\nEpoch 23/150\n28/28 [==============================] - 1s 38ms/step - loss: 6.9807e-04 - accuracy: 1.0000 - mae: 3.9099e-04 - val_loss: 1.9696 - val_accuracy: 0.6429 - val_mae: 0.2454\n\nEpoch 00023: val_accuracy did not improve from 0.78571\nEpoch 24/150\n28/28 [==============================] - 1s 39ms/step - loss: 5.2570e-04 - accuracy: 1.0000 - mae: 2.8495e-04 - val_loss: 1.3521 - val_accuracy: 0.7143 - val_mae: 0.1978\n\nEpoch 00024: val_accuracy did not improve from 0.78571\nEpoch 25/150\n28/28 [==============================] - 1s 39ms/step - loss: 4.1195e-04 - accuracy: 1.0000 - mae: 2.3078e-04 - val_loss: 1.8179 - val_accuracy: 0.7143 - val_mae: 0.1984\n\nEpoch 00025: val_accuracy did not improve from 0.78571\nEpoch 26/150\n28/28 [==============================] - 1s 39ms/step - loss: 3.2148e-04 - accuracy: 1.0000 - mae: 1.7365e-04 - val_loss: 2.1396 - val_accuracy: 0.6429 - val_mae: 0.2431\n\nEpoch 00026: val_accuracy did not improve from 0.78571\nEpoch 27/150\n28/28 [==============================] - 1s 39ms/step - loss: 2.4280e-04 - accuracy: 1.0000 - mae: 1.3002e-04 - val_loss: 2.2007 - val_accuracy: 0.6429 - val_mae: 0.2434\n\nEpoch 00027: val_accuracy did not improve from 0.78571\nEpoch 28/150\n28/28 [==============================] - 1s 40ms/step - loss: 1.9110e-04 - accuracy: 1.0000 - mae: 1.0602e-04 - val_loss: 2.2675 - val_accuracy: 0.6429 - val_mae: 0.2425\n\nEpoch 00028: val_accuracy did not improve from 0.78571\nEpoch 29/150\n28/28 [==============================] - 1s 42ms/step - loss: 1.4952e-04 - accuracy: 1.0000 - mae: 8.1241e-05 - val_loss: 2.3188 - val_accuracy: 0.6429 - val_mae: 0.2425\n\nEpoch 00029: val_accuracy did not improve from 0.78571\nEpoch 30/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.2013e-04 - accuracy: 1.0000 - mae: 6.4919e-05 - val_loss: 1.8672 - val_accuracy: 0.7143 - val_mae: 0.1952\n\nEpoch 00030: val_accuracy did not improve from 0.78571\nEpoch 31/150\n28/28 [==============================] - 1s 38ms/step - loss: 9.4616e-05 - accuracy: 1.0000 - mae: 5.0379e-05 - val_loss: 2.4174 - val_accuracy: 0.6429 - val_mae: 0.2417\n\nEpoch 00031: val_accuracy did not improve from 0.78571\nEpoch 32/150\n28/28 [==============================] - 1s 38ms/step - loss: 7.7482e-05 - accuracy: 1.0000 - mae: 4.1809e-05 - val_loss: 2.4703 - val_accuracy: 0.6429 - val_mae: 0.2413\n\nEpoch 00032: val_accuracy did not improve from 0.78571\nEpoch 33/150\n28/28 [==============================] - 1s 38ms/step - loss: 6.2798e-05 - accuracy: 1.0000 - mae: 3.2890e-05 - val_loss: 2.5084 - val_accuracy: 0.6429 - val_mae: 0.2407\n\nEpoch 00033: val_accuracy did not improve from 0.78571\nEpoch 34/150\n28/28 [==============================] - 1s 38ms/step - loss: 5.2563e-05 - accuracy: 1.0000 - mae: 2.7654e-05 - val_loss: 2.5483 - val_accuracy: 0.6429 - val_mae: 0.2379\n\nEpoch 00034: val_accuracy did not improve from 0.78571\nEpoch 35/150\n28/28 [==============================] - 1s 50ms/step - loss: 4.3867e-05 - accuracy: 1.0000 - mae: 2.3121e-05 - val_loss: 2.5846 - val_accuracy: 0.6429 - val_mae: 0.2379\n\nEpoch 00035: val_accuracy did not improve from 0.78571\nEpoch 36/150\n28/28 [==============================] - 1s 38ms/step - loss: 3.6969e-05 - accuracy: 1.0000 - mae: 1.9075e-05 - val_loss: 1.7365 - val_accuracy: 0.7143 - val_mae: 0.1928\n\nEpoch 00036: val_accuracy did not improve from 0.78571\nEpoch 37/150\n28/28 [==============================] - 1s 42ms/step - loss: 3.1648e-05 - accuracy: 1.0000 - mae: 1.6185e-05 - val_loss: 2.6561 - val_accuracy: 0.6429 - val_mae: 0.2404\n\nEpoch 00037: val_accuracy did not improve from 0.78571\nEpoch 38/150\n28/28 [==============================] - 1s 39ms/step - loss: 2.7363e-05 - accuracy: 1.0000 - mae: 1.4224e-05 - val_loss: 2.6885 - val_accuracy: 0.6429 - val_mae: 0.2402\n\nEpoch 00038: val_accuracy did not improve from 0.78571\nEpoch 39/150\n28/28 [==============================] - 1s 38ms/step - loss: 2.3960e-05 - accuracy: 1.0000 - mae: 1.2416e-05 - val_loss: 2.1264 - val_accuracy: 0.7143 - val_mae: 0.1925\n\nEpoch 00039: val_accuracy did not improve from 0.78571\nEpoch 40/150\n28/28 [==============================] - 1s 38ms/step - loss: 2.1210e-05 - accuracy: 1.0000 - mae: 1.1287e-05 - val_loss: 2.7449 - val_accuracy: 0.6429 - val_mae: 0.2401\n\nEpoch 00040: val_accuracy did not improve from 0.78571\nEpoch 41/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.8842e-05 - accuracy: 1.0000 - mae: 9.7311e-06 - val_loss: 2.7690 - val_accuracy: 0.6429 - val_mae: 0.2398\n\nEpoch 00041: val_accuracy did not improve from 0.78571\nEpoch 42/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.6640e-05 - accuracy: 1.0000 - mae: 8.4511e-06 - val_loss: 2.7926 - val_accuracy: 0.6429 - val_mae: 0.2399\n\nEpoch 00042: val_accuracy did not improve from 0.78571\nEpoch 43/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.4997e-05 - accuracy: 1.0000 - mae: 7.7453e-06 - val_loss: 2.8149 - val_accuracy: 0.6429 - val_mae: 0.2398\n\nEpoch 00043: val_accuracy did not improve from 0.78571\nEpoch 44/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.3670e-05 - accuracy: 1.0000 - mae: 6.9907e-06 - val_loss: 2.8373 - val_accuracy: 0.6429 - val_mae: 0.2396\n\nEpoch 00044: val_accuracy did not improve from 0.78571\nEpoch 45/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.2330e-05 - accuracy: 1.0000 - mae: 6.3898e-06 - val_loss: 2.8585 - val_accuracy: 0.6429 - val_mae: 0.2397\n\nEpoch 00045: val_accuracy did not improve from 0.78571\nEpoch 46/150\n28/28 [==============================] - 1s 42ms/step - loss: 1.1232e-05 - accuracy: 1.0000 - mae: 5.8115e-06 - val_loss: 2.8784 - val_accuracy: 0.6429 - val_mae: 0.2396\n\nEpoch 00046: val_accuracy did not improve from 0.78571\nEpoch 47/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.0402e-05 - accuracy: 1.0000 - mae: 5.3275e-06 - val_loss: 2.8985 - val_accuracy: 0.6429 - val_mae: 0.2394\n\nEpoch 00047: val_accuracy did not improve from 0.78571\nEpoch 48/150\n28/28 [==============================] - 1s 38ms/step - loss: 9.3759e-06 - accuracy: 1.0000 - mae: 4.8089e-06 - val_loss: 2.9171 - val_accuracy: 0.6429 - val_mae: 0.2395\n\nEpoch 00048: val_accuracy did not improve from 0.78571\nEpoch 49/150\n28/28 [==============================] - 1s 38ms/step - loss: 8.7588e-06 - accuracy: 1.0000 - mae: 4.5034e-06 - val_loss: 2.9345 - val_accuracy: 0.6429 - val_mae: 0.2393\n\nEpoch 00049: val_accuracy did not improve from 0.78571\nEpoch 50/150\n28/28 [==============================] - 1s 38ms/step - loss: 8.0609e-06 - accuracy: 1.0000 - mae: 4.1931e-06 - val_loss: 1.9524 - val_accuracy: 0.7143 - val_mae: 0.1918\n\nEpoch 00050: val_accuracy did not improve from 0.78571\nEpoch 51/150\n28/28 [==============================] - 1s 38ms/step - loss: 7.5346e-06 - accuracy: 1.0000 - mae: 3.9339e-06 - val_loss: 2.9688 - val_accuracy: 0.6429 - val_mae: 0.2392\n\nEpoch 00051: val_accuracy did not improve from 0.78571\nEpoch 52/150\n28/28 [==============================] - 1s 38ms/step - loss: 6.9453e-06 - accuracy: 1.0000 - mae: 3.5887e-06 - val_loss: 2.9865 - val_accuracy: 0.6429 - val_mae: 0.2393\n\nEpoch 00052: val_accuracy did not improve from 0.78571\nEpoch 53/150\n28/28 [==============================] - 1s 38ms/step - loss: 6.4743e-06 - accuracy: 1.0000 - mae: 3.3228e-06 - val_loss: 2.9988 - val_accuracy: 0.6429 - val_mae: 0.2380\n\nEpoch 00053: val_accuracy did not improve from 0.78571\nEpoch 54/150\n28/28 [==============================] - 1s 38ms/step - loss: 6.0983e-06 - accuracy: 1.0000 - mae: 3.1173e-06 - val_loss: 3.0151 - val_accuracy: 0.6429 - val_mae: 0.2392\n\nEpoch 00054: val_accuracy did not improve from 0.78571\nEpoch 55/150\n28/28 [==============================] - 1s 39ms/step - loss: 5.6755e-06 - accuracy: 1.0000 - mae: 2.9110e-06 - val_loss: 2.5438 - val_accuracy: 0.7143 - val_mae: 0.1916\n\nEpoch 00055: val_accuracy did not improve from 0.78571\nEpoch 56/150\n28/28 [==============================] - 1s 40ms/step - loss: 5.3859e-06 - accuracy: 1.0000 - mae: 2.7183e-06 - val_loss: 3.0440 - val_accuracy: 0.6429 - val_mae: 0.2391\n\nEpoch 00056: val_accuracy did not improve from 0.78571\nEpoch 57/150\n28/28 [==============================] - 1s 39ms/step - loss: 5.0348e-06 - accuracy: 1.0000 - mae: 2.5713e-06 - val_loss: 2.0190 - val_accuracy: 0.7143 - val_mae: 0.1915\n\nEpoch 00057: val_accuracy did not improve from 0.78571\nEpoch 58/150\n28/28 [==============================] - 1s 38ms/step - loss: 4.7052e-06 - accuracy: 1.0000 - mae: 2.4302e-06 - val_loss: 2.4006 - val_accuracy: 0.7143 - val_mae: 0.1915\n\nEpoch 00058: val_accuracy did not improve from 0.78571\nEpoch 59/150\n28/28 [==============================] - 1s 38ms/step - loss: 4.5367e-06 - accuracy: 1.0000 - mae: 2.2922e-06 - val_loss: 3.0834 - val_accuracy: 0.6429 - val_mae: 0.2390\n\nEpoch 00059: val_accuracy did not improve from 0.78571\nEpoch 60/150\n28/28 [==============================] - 1s 43ms/step - loss: 4.2067e-06 - accuracy: 1.0000 - mae: 2.1588e-06 - val_loss: 3.0952 - val_accuracy: 0.6429 - val_mae: 0.2391\n\nEpoch 00060: val_accuracy did not improve from 0.78571\nEpoch 61/150\n28/28 [==============================] - 1s 47ms/step - loss: 4.0072e-06 - accuracy: 1.0000 - mae: 2.0589e-06 - val_loss: 2.0510 - val_accuracy: 0.7143 - val_mae: 0.1914\n\nEpoch 00061: val_accuracy did not improve from 0.78571\nEpoch 62/150\n28/28 [==============================] - 1s 38ms/step - loss: 3.8173e-06 - accuracy: 1.0000 - mae: 1.9393e-06 - val_loss: 3.1174 - val_accuracy: 0.6429 - val_mae: 0.2380\n\nEpoch 00062: val_accuracy did not improve from 0.78571\nEpoch 63/150\n28/28 [==============================] - 1s 40ms/step - loss: 3.5729e-06 - accuracy: 1.0000 - mae: 1.8200e-06 - val_loss: 2.6457 - val_accuracy: 0.7143 - val_mae: 0.1914\n\nEpoch 00063: val_accuracy did not improve from 0.78571\nEpoch 64/150\n28/28 [==============================] - 1s 42ms/step - loss: 3.4015e-06 - accuracy: 1.0000 - mae: 1.7548e-06 - val_loss: 3.1416 - val_accuracy: 0.6429 - val_mae: 0.2390\n\nEpoch 00064: val_accuracy did not improve from 0.78571\nEpoch 65/150\n28/28 [==============================] - 1s 39ms/step - loss: 3.2520e-06 - accuracy: 1.0000 - mae: 1.6762e-06 - val_loss: 3.1514 - val_accuracy: 0.6429 - val_mae: 0.2390\n\nEpoch 00065: val_accuracy did not improve from 0.78571\nEpoch 66/150\n28/28 [==============================] - 1s 38ms/step - loss: 3.1097e-06 - accuracy: 1.0000 - mae: 1.5979e-06 - val_loss: 2.0875 - val_accuracy: 0.7143 - val_mae: 0.1913\n\nEpoch 00066: val_accuracy did not improve from 0.78571\nEpoch 67/150\n28/28 [==============================] - 1s 38ms/step - loss: 2.9694e-06 - accuracy: 1.0000 - mae: 1.5030e-06 - val_loss: 2.6653 - val_accuracy: 0.7143 - val_mae: 0.1913\n\nEpoch 00067: val_accuracy did not improve from 0.78571\nEpoch 68/150\n28/28 [==============================] - 1s 38ms/step - loss: 2.8005e-06 - accuracy: 1.0000 - mae: 1.4243e-06 - val_loss: 3.1868 - val_accuracy: 0.6429 - val_mae: 0.2389\n\nEpoch 00068: val_accuracy did not improve from 0.78571\nEpoch 69/150\n28/28 [==============================] - 1s 38ms/step - loss: 2.6787e-06 - accuracy: 1.0000 - mae: 1.3621e-06 - val_loss: 2.7015 - val_accuracy: 0.7143 - val_mae: 0.1913\n\nEpoch 00069: val_accuracy did not improve from 0.78571\nEpoch 70/150\n28/28 [==============================] - 1s 38ms/step - loss: 2.5252e-06 - accuracy: 1.0000 - mae: 1.2795e-06 - val_loss: 2.6944 - val_accuracy: 0.7143 - val_mae: 0.1912\n\nEpoch 00070: val_accuracy did not improve from 0.78571\nEpoch 71/150\n28/28 [==============================] - 1s 39ms/step - loss: 2.4042e-06 - accuracy: 1.0000 - mae: 1.2197e-06 - val_loss: 3.2187 - val_accuracy: 0.6429 - val_mae: 0.2388\n\nEpoch 00071: val_accuracy did not improve from 0.78571\nEpoch 72/150\n28/28 [==============================] - 1s 39ms/step - loss: 2.3090e-06 - accuracy: 1.0000 - mae: 1.1722e-06 - val_loss: 3.2285 - val_accuracy: 0.6429 - val_mae: 0.2388\n\nEpoch 00072: val_accuracy did not improve from 0.78571\nEpoch 73/150\n28/28 [==============================] - 1s 43ms/step - loss: 2.1947e-06 - accuracy: 1.0000 - mae: 1.1171e-06 - val_loss: 3.2390 - val_accuracy: 0.6429 - val_mae: 0.2388\n\nEpoch 00073: val_accuracy did not improve from 0.78571\nEpoch 74/150\n28/28 [==============================] - 1s 39ms/step - loss: 2.1179e-06 - accuracy: 1.0000 - mae: 1.0636e-06 - val_loss: 2.1380 - val_accuracy: 0.7143 - val_mae: 0.1911\n\nEpoch 00074: val_accuracy did not improve from 0.78571\nEpoch 75/150\n28/28 [==============================] - 1s 38ms/step - loss: 2.0180e-06 - accuracy: 1.0000 - mae: 1.0233e-06 - val_loss: 3.2570 - val_accuracy: 0.6429 - val_mae: 0.2388\n\nEpoch 00075: val_accuracy did not improve from 0.78571\nEpoch 76/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.9371e-06 - accuracy: 1.0000 - mae: 9.8372e-07 - val_loss: 3.2673 - val_accuracy: 0.6429 - val_mae: 0.2388\n\nEpoch 00076: val_accuracy did not improve from 0.78571\nEpoch 77/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.8359e-06 - accuracy: 1.0000 - mae: 9.3164e-07 - val_loss: 3.2754 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00077: val_accuracy did not improve from 0.78571\nEpoch 78/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.7791e-06 - accuracy: 1.0000 - mae: 9.0560e-07 - val_loss: 3.2853 - val_accuracy: 0.6429 - val_mae: 0.2388\n\nEpoch 00078: val_accuracy did not improve from 0.78571\nEpoch 79/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.7122e-06 - accuracy: 1.0000 - mae: 8.6649e-07 - val_loss: 3.2938 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00079: val_accuracy did not improve from 0.78571\nEpoch 80/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.6450e-06 - accuracy: 1.0000 - mae: 8.3605e-07 - val_loss: 3.3026 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00080: val_accuracy did not improve from 0.78571\nEpoch 81/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.5691e-06 - accuracy: 1.0000 - mae: 8.0194e-07 - val_loss: 3.3114 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00081: val_accuracy did not improve from 0.78571\nEpoch 82/150\n28/28 [==============================] - 1s 40ms/step - loss: 1.5204e-06 - accuracy: 1.0000 - mae: 7.7322e-07 - val_loss: 3.3187 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00082: val_accuracy did not improve from 0.78571\nEpoch 83/150\n28/28 [==============================] - 1s 41ms/step - loss: 1.4644e-06 - accuracy: 1.0000 - mae: 7.4233e-07 - val_loss: 3.3275 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00083: val_accuracy did not improve from 0.78571\nEpoch 84/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.4059e-06 - accuracy: 1.0000 - mae: 7.1911e-07 - val_loss: 2.7976 - val_accuracy: 0.7143 - val_mae: 0.1911\n\nEpoch 00084: val_accuracy did not improve from 0.78571\nEpoch 85/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.3578e-06 - accuracy: 1.0000 - mae: 6.9011e-07 - val_loss: 3.3428 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00085: val_accuracy did not improve from 0.78571\nEpoch 86/150\n28/28 [==============================] - 1s 45ms/step - loss: 1.3235e-06 - accuracy: 1.0000 - mae: 6.7352e-07 - val_loss: 3.3516 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00086: val_accuracy did not improve from 0.78571\nEpoch 87/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.2788e-06 - accuracy: 1.0000 - mae: 6.5292e-07 - val_loss: 3.3602 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00087: val_accuracy did not improve from 0.78571\nEpoch 88/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.2235e-06 - accuracy: 1.0000 - mae: 6.2228e-07 - val_loss: 2.8424 - val_accuracy: 0.7143 - val_mae: 0.1911\n\nEpoch 00088: val_accuracy did not improve from 0.78571\nEpoch 89/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.1878e-06 - accuracy: 1.0000 - mae: 6.0328e-07 - val_loss: 3.3756 - val_accuracy: 0.6429 - val_mae: 0.2387\n\nEpoch 00089: val_accuracy did not improve from 0.78571\nEpoch 90/150\n28/28 [==============================] - 1s 40ms/step - loss: 1.1430e-06 - accuracy: 1.0000 - mae: 5.8349e-07 - val_loss: 3.3813 - val_accuracy: 0.6429 - val_mae: 0.2380\n\nEpoch 00090: val_accuracy did not improve from 0.78571\nEpoch 91/150\n28/28 [==============================] - 1s 39ms/step - loss: 1.1132e-06 - accuracy: 1.0000 - mae: 5.6283e-07 - val_loss: 2.8494 - val_accuracy: 0.7143 - val_mae: 0.1910\n\nEpoch 00091: val_accuracy did not improve from 0.78571\nEpoch 92/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.0661e-06 - accuracy: 1.0000 - mae: 5.4110e-07 - val_loss: 2.8659 - val_accuracy: 0.7143 - val_mae: 0.1910\n\nEpoch 00092: val_accuracy did not improve from 0.78571\nEpoch 93/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.0287e-06 - accuracy: 1.0000 - mae: 5.2183e-07 - val_loss: 2.6588 - val_accuracy: 0.7143 - val_mae: 0.1910\n\nEpoch 00093: val_accuracy did not improve from 0.78571\nEpoch 94/150\n28/28 [==============================] - 1s 38ms/step - loss: 1.0019e-06 - accuracy: 1.0000 - mae: 5.0739e-07 - val_loss: 3.4117 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00094: val_accuracy did not improve from 0.78571\nEpoch 95/150\n28/28 [==============================] - 1s 39ms/step - loss: 9.7177e-07 - accuracy: 1.0000 - mae: 4.9379e-07 - val_loss: 3.4194 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00095: val_accuracy did not improve from 0.78571\nEpoch 96/150\n28/28 [==============================] - 1s 38ms/step - loss: 9.5190e-07 - accuracy: 1.0000 - mae: 4.8068e-07 - val_loss: 2.8902 - val_accuracy: 0.7143 - val_mae: 0.1910\n\nEpoch 00096: val_accuracy did not improve from 0.78571\nEpoch 97/150\n28/28 [==============================] - 1s 38ms/step - loss: 9.2671e-07 - accuracy: 1.0000 - mae: 4.7360e-07 - val_loss: 2.6800 - val_accuracy: 0.7143 - val_mae: 0.1910\n\nEpoch 00097: val_accuracy did not improve from 0.78571\nEpoch 98/150\n28/28 [==============================] - 1s 39ms/step - loss: 8.8751e-07 - accuracy: 1.0000 - mae: 4.4867e-07 - val_loss: 3.4405 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00098: val_accuracy did not improve from 0.78571\nEpoch 99/150\n28/28 [==============================] - 1s 39ms/step - loss: 8.6036e-07 - accuracy: 1.0000 - mae: 4.3632e-07 - val_loss: 3.4457 - val_accuracy: 0.6429 - val_mae: 0.2380\n\nEpoch 00099: val_accuracy did not improve from 0.78571\nEpoch 100/150\n28/28 [==============================] - 1s 43ms/step - loss: 8.3695e-07 - accuracy: 1.0000 - mae: 4.2753e-07 - val_loss: 3.4533 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00100: val_accuracy did not improve from 0.78571\nEpoch 101/150\n28/28 [==============================] - 1s 39ms/step - loss: 8.0519e-07 - accuracy: 1.0000 - mae: 4.1261e-07 - val_loss: 3.4601 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00101: val_accuracy did not improve from 0.78571\nEpoch 102/150\n28/28 [==============================] - 1s 39ms/step - loss: 7.7752e-07 - accuracy: 1.0000 - mae: 3.9677e-07 - val_loss: 3.4670 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00102: val_accuracy did not improve from 0.78571\nEpoch 103/150\n28/28 [==============================] - 1s 39ms/step - loss: 7.5464e-07 - accuracy: 1.0000 - mae: 3.8304e-07 - val_loss: 3.4729 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00103: val_accuracy did not improve from 0.78571\nEpoch 104/150\n28/28 [==============================] - 1s 39ms/step - loss: 7.4665e-07 - accuracy: 1.0000 - mae: 3.7605e-07 - val_loss: 3.4799 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00104: val_accuracy did not improve from 0.78571\nEpoch 105/150\n28/28 [==============================] - 1s 39ms/step - loss: 7.1809e-07 - accuracy: 1.0000 - mae: 3.6327e-07 - val_loss: 3.4861 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00105: val_accuracy did not improve from 0.78571\nEpoch 106/150\n28/28 [==============================] - 1s 39ms/step - loss: 7.0443e-07 - accuracy: 1.0000 - mae: 3.5839e-07 - val_loss: 3.4923 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00106: val_accuracy did not improve from 0.78571\nEpoch 107/150\n28/28 [==============================] - 1s 39ms/step - loss: 6.6949e-07 - accuracy: 1.0000 - mae: 3.4545e-07 - val_loss: 3.4980 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00107: val_accuracy did not improve from 0.78571\nEpoch 108/150\n28/28 [==============================] - 1s 41ms/step - loss: 6.7250e-07 - accuracy: 1.0000 - mae: 3.3951e-07 - val_loss: 3.5049 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00108: val_accuracy did not improve from 0.78571\nEpoch 109/150\n28/28 [==============================] - 1s 42ms/step - loss: 6.3206e-07 - accuracy: 1.0000 - mae: 3.2852e-07 - val_loss: 3.5104 - val_accuracy: 0.6429 - val_mae: 0.2386\n\nEpoch 00109: val_accuracy did not improve from 0.78571\nEpoch 110/150\n28/28 [==============================] - 1s 39ms/step - loss: 6.0846e-07 - accuracy: 1.0000 - mae: 3.1655e-07 - val_loss: 2.3126 - val_accuracy: 0.7143 - val_mae: 0.1909\n\nEpoch 00110: val_accuracy did not improve from 0.78571\nEpoch 111/150\n28/28 [==============================] - 1s 53ms/step - loss: 5.9409e-07 - accuracy: 1.0000 - mae: 3.0729e-07 - val_loss: 3.0969 - val_accuracy: 0.7143 - val_mae: 0.1910\n\nEpoch 00111: val_accuracy did not improve from 0.78571\nEpoch 112/150\n28/28 [==============================] - 1s 40ms/step - loss: 5.8984e-07 - accuracy: 1.0000 - mae: 3.0235e-07 - val_loss: 2.3199 - val_accuracy: 0.7143 - val_mae: 0.1909\n\nEpoch 00112: val_accuracy did not improve from 0.78571\nEpoch 113/150\n28/28 [==============================] - 1s 39ms/step - loss: 5.7706e-07 - accuracy: 1.0000 - mae: 2.9283e-07 - val_loss: 3.5351 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00113: val_accuracy did not improve from 0.78571\nEpoch 114/150\n28/28 [==============================] - 1s 39ms/step - loss: 5.5560e-07 - accuracy: 1.0000 - mae: 2.8305e-07 - val_loss: 2.9849 - val_accuracy: 0.7143 - val_mae: 0.1909\n\nEpoch 00114: val_accuracy did not improve from 0.78571\nEpoch 115/150\n28/28 [==============================] - 1s 38ms/step - loss: 5.4691e-07 - accuracy: 1.0000 - mae: 2.7930e-07 - val_loss: 3.5457 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00115: val_accuracy did not improve from 0.78571\nEpoch 116/150\n28/28 [==============================] - 1s 39ms/step - loss: 5.2686e-07 - accuracy: 1.0000 - mae: 2.7135e-07 - val_loss: 3.5526 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00116: val_accuracy did not improve from 0.78571\nEpoch 117/150\n28/28 [==============================] - 1s 40ms/step - loss: 5.1107e-07 - accuracy: 1.0000 - mae: 2.6131e-07 - val_loss: 2.9883 - val_accuracy: 0.7143 - val_mae: 0.1909\n\nEpoch 00117: val_accuracy did not improve from 0.78571\nEpoch 118/150\n28/28 [==============================] - 1s 43ms/step - loss: 5.0398e-07 - accuracy: 1.0000 - mae: 2.5632e-07 - val_loss: 3.5639 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00118: val_accuracy did not improve from 0.78571\nEpoch 119/150\n28/28 [==============================] - 1s 39ms/step - loss: 4.9262e-07 - accuracy: 1.0000 - mae: 2.5010e-07 - val_loss: 3.5697 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00119: val_accuracy did not improve from 0.78571\nEpoch 120/150\n28/28 [==============================] - 1s 39ms/step - loss: 4.7897e-07 - accuracy: 1.0000 - mae: 2.4636e-07 - val_loss: 2.9993 - val_accuracy: 0.7143 - val_mae: 0.1909\n\nEpoch 00120: val_accuracy did not improve from 0.78571\nEpoch 121/150\n28/28 [==============================] - 1s 39ms/step - loss: 4.7258e-07 - accuracy: 1.0000 - mae: 2.4084e-07 - val_loss: 3.5800 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00121: val_accuracy did not improve from 0.78571\nEpoch 122/150\n28/28 [==============================] - 1s 39ms/step - loss: 4.5484e-07 - accuracy: 1.0000 - mae: 2.3257e-07 - val_loss: 3.5856 - val_accuracy: 0.6429 - val_mae: 0.2384\n\nEpoch 00122: val_accuracy did not improve from 0.78571\nEpoch 123/150\n28/28 [==============================] - 1s 38ms/step - loss: 4.3373e-07 - accuracy: 1.0000 - mae: 2.2761e-07 - val_loss: 3.5909 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00123: val_accuracy did not improve from 0.78571\nEpoch 124/150\n28/28 [==============================] - 1s 38ms/step - loss: 4.3231e-07 - accuracy: 1.0000 - mae: 2.2247e-07 - val_loss: 2.8125 - val_accuracy: 0.7143 - val_mae: 0.1909\n\nEpoch 00124: val_accuracy did not improve from 0.78571\nEpoch 125/150\n28/28 [==============================] - 1s 38ms/step - loss: 4.2096e-07 - accuracy: 1.0000 - mae: 2.1627e-07 - val_loss: 3.1689 - val_accuracy: 0.7143 - val_mae: 0.1910\n\nEpoch 00125: val_accuracy did not improve from 0.78571\nEpoch 126/150\n28/28 [==============================] - 1s 39ms/step - loss: 4.2522e-07 - accuracy: 1.0000 - mae: 2.1749e-07 - val_loss: 3.6066 - val_accuracy: 0.6429 - val_mae: 0.2385\n\nEpoch 00126: val_accuracy did not improve from 0.78571\nEpoch 127/150\n27/28 [===========================>..] - ETA: 0s - loss: 3.9681e-07 - accuracy: 1.0000 - mae: 1.9484e-07","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1719/2880277506.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  epochs=150,callbacks=[checkpoint])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1224\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1227\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_recreate_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m           \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 719\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3121\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"**Loading model weights**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nbest_model=load_model('/kaggle/working/vgg16_base_res_QF.h5')","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.265303Z","iopub.status.idle":"2022-12-08T20:26:22.266529Z","shell.execute_reply.started":"2022-12-08T20:26:22.266256Z","shell.execute_reply":"2022-12-08T20:26:22.266294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Getting prediction**","metadata":{}},{"cell_type":"code","source":"tsdata = ImageDataGenerator(rescale=1./255)\ntestdata = tsdata.flow_from_directory(directory=test_loc, target_size=(224,224),batch_size=2,shuffle=False)\nfrom sklearn.metrics import classification_report, confusion_matrix\nY_pred = best_model.predict_generator(testdata,testdata.samples//testdata.batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.268102Z","iopub.status.idle":"2022-12-08T20:26:22.268607Z","shell.execute_reply.started":"2022-12-08T20:26:22.268346Z","shell.execute_reply":"2022-12-08T20:26:22.268369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Saving results in csv**","metadata":{}},{"cell_type":"code","source":"from numpy import savetxt\nsavetxt('working/Y_pred_BF.csv', Y_pred_BF, delimiter=',')","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.295744Z","iopub.status.idle":"2022-12-08T20:26:22.296716Z","shell.execute_reply.started":"2022-12-08T20:26:22.296447Z","shell.execute_reply":"2022-12-08T20:26:22.296473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CLassification report or result analysis**","metadata":{}},{"cell_type":"code","source":"tsdata = ImageDataGenerator(rescale=1./255)\ntestdata = tsdata.flow_from_directory(directory=test_loc, target_size=(224,224),batch_size=2,shuffle=False)\nfrom sklearn.metrics import classification_report, confusion_matrix\nY_pred = best_model.predict_generator(testdata,testdata.samples//testdata.batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\ncf_mat=confusion_matrix(testdata.classes, y_pred)\nprint(confusion_matrix(testdata.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['Flat Foot','Normal','Toe First']\nprint(classification_report(testdata.classes, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.302426Z","iopub.status.idle":"2022-12-08T20:26:22.302929Z","shell.execute_reply.started":"2022-12-08T20:26:22.302671Z","shell.execute_reply":"2022-12-08T20:26:22.302693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Combining results from 4 muscles","metadata":{}},{"cell_type":"code","source":"Y_pred_c4 = (Y_pred_Tibialis+Y_pred_QF+Y_pred_GM+y_pred_BF)/4","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.30489Z","iopub.status.idle":"2022-12-08T20:26:22.305403Z","shell.execute_reply.started":"2022-12-08T20:26:22.305138Z","shell.execute_reply":"2022-12-08T20:26:22.30516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Total Results**","metadata":{}},{"cell_type":"code","source":"\ny_pred = np.argmax(Y_pred_QF, axis=1)\nprint('Confusion Matrix')\ncf_mat=confusion_matrix(testdata.classes, y_pred)\nprint(confusion_matrix(testdata.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['Flat_foot', 'Normal','ToeFirst']\nprint(classification_report(testdata.classes, y_pred, target_names=target_names))","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.307399Z","iopub.status.idle":"2022-12-08T20:26:22.307903Z","shell.execute_reply.started":"2022-12-08T20:26:22.307648Z","shell.execute_reply":"2022-12-08T20:26:22.307671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# results using colored table","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    '''\n    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n    Arguments\n    ---------\n    cf:            confusion matrix to be passed in\n    group_names:   List of strings that represent the labels row by row to be shown in each square.\n    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n    count:         If True, show the raw number in the confusion matrix. Default is True.\n    normalize:     If True, show the proportions for each category. Default is True.\n    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n                   Default is True.\n    xyticks:       If True, show x and y ticks. Default is True.\n    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n    sum_stats:     If True, display summary statistics below the figure. Default is True.\n    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n                   See http://matplotlib.org/examples/color/colormaps_reference.html\n                   \n    title:         Title for the heatmap. Default is None.\n    '''\n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) / float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] / sum(cf[:,1])\n            recall    = cf[1,1] / sum(cf[1,:])\n            f1_score  = 2*precision*recall / (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)\n    plt.savefig('working/VGG-imf-ind10.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.309889Z","iopub.status.idle":"2022-12-08T20:26:22.310365Z","shell.execute_reply.started":"2022-12-08T20:26:22.31012Z","shell.execute_reply":"2022-12-08T20:26:22.310143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories = ['Flat Foot','Normal','Toe First']\nmake_confusion_matrix(cf_mat, categories=categories, figsize=(10,8),cbar=False, title='Confusion matrix of VGG16 from EMG data')","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.312329Z","iopub.status.idle":"2022-12-08T20:26:22.312841Z","shell.execute_reply.started":"2022-12-08T20:26:22.312588Z","shell.execute_reply":"2022-12-08T20:26:22.312611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training graph**","metadata":{}},{"cell_type":"code","source":"# Visualize history\nimport matplotlib.pyplot as plt\n# Plot history: Loss\nplt.plot(hist.history['val_loss'])\nplt.title('Validation loss history')\nplt.ylabel('Loss value')\nplt.xlabel('No. epoch')\nplt.savefig('working/2.jpg')\nplt.show()\n# Plot history: Accuracy\nplt.plot(hist.history['val_accuracy'])\nplt.title('Validation accuracy history')\nplt.ylabel('Accuracy value (%)')\nplt.xlabel('No. epoch')\nplt.savefig('working/3.jpg')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.315183Z","iopub.status.idle":"2022-12-08T20:26:22.315677Z","shell.execute_reply.started":"2022-12-08T20:26:22.315413Z","shell.execute_reply":"2022-12-08T20:26:22.315436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And lastly we want to visualise how our model is learning. Plot the loss, accuracy, and mae as follows:","metadata":{}},{"cell_type":"code","source":"plt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='val')\nplt.title('VGG16: Loss and Validation Loss (0.000001 = Adam LR)')\nplt.legend();\nplt.savefig('working/4.jpg')\nplt.show()\n\nplt.plot(hist.history['accuracy'], label='train')\nplt.plot(hist.history['val_accuracy'], label='val')\nplt.title('VGG16: Accuracy and Validation Accuracy (0.000001 = Adam LR)')\nplt.legend();\nplt.savefig('working/5.jpg')\nplt.show()\n\nplt.plot(hist.history['mae'], label='train')\nplt.plot(hist.history['val_mae'], label='val')\nplt.title('VGG16: MAE and Validation MAE (0.000001 = Adam LR)')\nplt.legend();\nplt.savefig('working/6.jpg')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-08T20:26:22.317582Z","iopub.status.idle":"2022-12-08T20:26:22.318069Z","shell.execute_reply.started":"2022-12-08T20:26:22.317821Z","shell.execute_reply":"2022-12-08T20:26:22.317844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that slowly but surely our model is learning our data. Validation accuracy is increasing steadily while mean absolute error is decreasing. However, we should be aware that loss is increasing. In this context, but maybe we can just ditch loss since we are already looking at mae.\n\nAnd that's that! If you're following this series, thank you so much! Please upvote if this helped you in any way.\n","metadata":{}}]}